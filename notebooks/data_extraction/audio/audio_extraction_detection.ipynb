{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "videos_dir = None\n",
    "save_dir_all = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "dir_path = os.getcwd()\n",
    "\n",
    "if not videos_dir:\n",
    "    if 'google.colab' in str(get_ipython()):\n",
    "        # Update this path as necessary\n",
    "        videos_dir = f'{dir_path}/AIC_Video'\n",
    "    elif 'kaggle' in str(get_ipython()):\n",
    "        videos_dir = f'{dir_path}/AIC_Video'\n",
    "    else:\n",
    "        parent_dir_path = os.path.dirname(dir_path)\n",
    "        videos_dir = f'{parent_dir_path}/dataset/AIC_Video'\n",
    "        \n",
    "if not save_dir_all:\n",
    "    save_dir_all = f'{dir_path}/Audio'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ffmpeg-python in /home/heigatvu/my-project/competition/HCMC-AI/pipeline-hcm-ai/venv/lib/python3.9/site-packages (0.2.0)\n",
      "Requirement already satisfied: future in /home/heigatvu/my-project/competition/HCMC-AI/pipeline-hcm-ai/venv/lib/python3.9/site-packages (from ffmpeg-python) (1.0.0)\n",
      "\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: pyannote.audio in /home/heigatvu/my-project/competition/HCMC-AI/pipeline-hcm-ai/venv/lib/python3.9/site-packages (3.3.1)\n",
      "Requirement already satisfied: omegaconf<3.0,>=2.1 in /home/heigatvu/my-project/competition/HCMC-AI/pipeline-hcm-ai/venv/lib/python3.9/site-packages (from pyannote.audio) (2.3.0)\n",
      "Requirement already satisfied: torch>=2.0.0 in /home/heigatvu/my-project/competition/HCMC-AI/pipeline-hcm-ai/venv/lib/python3.9/site-packages (from pyannote.audio) (2.3.1)\n",
      "Requirement already satisfied: pyannote.metrics>=3.2 in /home/heigatvu/my-project/competition/HCMC-AI/pipeline-hcm-ai/venv/lib/python3.9/site-packages (from pyannote.audio) (3.2.1)\n",
      "Requirement already satisfied: einops>=0.6.0 in /home/heigatvu/my-project/competition/HCMC-AI/pipeline-hcm-ai/venv/lib/python3.9/site-packages (from pyannote.audio) (0.8.0)\n",
      "Requirement already satisfied: pyannote.pipeline>=3.0.1 in /home/heigatvu/my-project/competition/HCMC-AI/pipeline-hcm-ai/venv/lib/python3.9/site-packages (from pyannote.audio) (3.0.1)\n",
      "Requirement already satisfied: torchmetrics>=0.11.0 in /home/heigatvu/my-project/competition/HCMC-AI/pipeline-hcm-ai/venv/lib/python3.9/site-packages (from pyannote.audio) (1.4.1)\n",
      "Requirement already satisfied: torch-audiomentations>=0.11.0 in /home/heigatvu/my-project/competition/HCMC-AI/pipeline-hcm-ai/venv/lib/python3.9/site-packages (from pyannote.audio) (0.11.1)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in /home/heigatvu/my-project/competition/HCMC-AI/pipeline-hcm-ai/venv/lib/python3.9/site-packages (from pyannote.audio) (0.12.1)\n",
      "Requirement already satisfied: pyannote.core>=5.0.0 in /home/heigatvu/my-project/competition/HCMC-AI/pipeline-hcm-ai/venv/lib/python3.9/site-packages (from pyannote.audio) (5.0.0)\n",
      "Requirement already satisfied: pytorch-metric-learning>=2.1.0 in /home/heigatvu/my-project/competition/HCMC-AI/pipeline-hcm-ai/venv/lib/python3.9/site-packages (from pyannote.audio) (2.6.0)\n",
      "Requirement already satisfied: speechbrain>=1.0.0 in /home/heigatvu/my-project/competition/HCMC-AI/pipeline-hcm-ai/venv/lib/python3.9/site-packages (from pyannote.audio) (1.0.0)\n",
      "Requirement already satisfied: torchaudio>=2.2.0 in /home/heigatvu/my-project/competition/HCMC-AI/pipeline-hcm-ai/venv/lib/python3.9/site-packages (from pyannote.audio) (2.3.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.13.0 in /home/heigatvu/my-project/competition/HCMC-AI/pipeline-hcm-ai/venv/lib/python3.9/site-packages (from pyannote.audio) (0.24.5)\n",
      "Requirement already satisfied: asteroid-filterbanks>=0.4 in /home/heigatvu/my-project/competition/HCMC-AI/pipeline-hcm-ai/venv/lib/python3.9/site-packages (from pyannote.audio) (0.4.0)\n",
      "Requirement already satisfied: tensorboardX>=2.6 in /home/heigatvu/my-project/competition/HCMC-AI/pipeline-hcm-ai/venv/lib/python3.9/site-packages (from pyannote.audio) (2.6.2.2)\n",
      "Requirement already satisfied: lightning>=2.0.1 in /home/heigatvu/my-project/competition/HCMC-AI/pipeline-hcm-ai/venv/lib/python3.9/site-packages (from pyannote.audio) (2.4.0)\n",
      "Requirement already satisfied: rich>=12.0.0 in /home/heigatvu/my-project/competition/HCMC-AI/pipeline-hcm-ai/venv/lib/python3.9/site-packages (from pyannote.audio) (13.7.1)\n",
      "Requirement already satisfied: semver>=3.0.0 in /home/heigatvu/my-project/competition/HCMC-AI/pipeline-hcm-ai/venv/lib/python3.9/site-packages (from pyannote.audio) (3.0.2)\n",
      "Requirement already satisfied: pyannote.database>=5.0.1 in /home/heigatvu/my-project/competition/HCMC-AI/pipeline-hcm-ai/venv/lib/python3.9/site-packages (from pyannote.audio) (5.1.0)\n",
      "Requirement already satisfied: numpy in /home/heigatvu/my-project/competition/HCMC-AI/pipeline-hcm-ai/venv/lib/python3.9/site-packages (from asteroid-filterbanks>=0.4->pyannote.audio) (1.23.3)\n",
      "Requirement already satisfied: typing-extensions in /home/heigatvu/my-project/competition/HCMC-AI/pipeline-hcm-ai/venv/lib/python3.9/site-packages (from asteroid-filterbanks>=0.4->pyannote.audio) (4.12.2)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/heigatvu/my-project/competition/HCMC-AI/pipeline-hcm-ai/venv/lib/python3.9/site-packages (from huggingface-hub>=0.13.0->pyannote.audio) (24.1)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/heigatvu/my-project/competition/HCMC-AI/pipeline-hcm-ai/venv/lib/python3.9/site-packages (from huggingface-hub>=0.13.0->pyannote.audio) (4.64.1)\n",
      "Requirement already satisfied: requests in /home/heigatvu/my-project/competition/HCMC-AI/pipeline-hcm-ai/venv/lib/python3.9/site-packages (from huggingface-hub>=0.13.0->pyannote.audio) (2.32.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/heigatvu/my-project/competition/HCMC-AI/pipeline-hcm-ai/venv/lib/python3.9/site-packages (from huggingface-hub>=0.13.0->pyannote.audio) (2024.6.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/heigatvu/my-project/competition/HCMC-AI/pipeline-hcm-ai/venv/lib/python3.9/site-packages (from huggingface-hub>=0.13.0->pyannote.audio) (6.0.2)\n",
      "Requirement already satisfied: filelock in /home/heigatvu/my-project/competition/HCMC-AI/pipeline-hcm-ai/venv/lib/python3.9/site-packages (from huggingface-hub>=0.13.0->pyannote.audio) (3.15.4)\n",
      "Requirement already satisfied: pytorch-lightning in /home/heigatvu/my-project/competition/HCMC-AI/pipeline-hcm-ai/venv/lib/python3.9/site-packages (from lightning>=2.0.1->pyannote.audio) (2.4.0)\n",
      "Requirement already satisfied: lightning-utilities<2.0,>=0.10.0 in /home/heigatvu/my-project/competition/HCMC-AI/pipeline-hcm-ai/venv/lib/python3.9/site-packages (from lightning>=2.0.1->pyannote.audio) (0.11.6)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /home/heigatvu/my-project/competition/HCMC-AI/pipeline-hcm-ai/venv/lib/python3.9/site-packages (from omegaconf<3.0,>=2.1->pyannote.audio) (4.9.3)\n",
      "Requirement already satisfied: sortedcontainers>=2.0.4 in /home/heigatvu/my-project/competition/HCMC-AI/pipeline-hcm-ai/venv/lib/python3.9/site-packages (from pyannote.core>=5.0.0->pyannote.audio) (2.4.0)\n",
      "Requirement already satisfied: scipy>=1.1 in /home/heigatvu/my-project/competition/HCMC-AI/pipeline-hcm-ai/venv/lib/python3.9/site-packages (from pyannote.core>=5.0.0->pyannote.audio) (1.13.1)\n",
      "Requirement already satisfied: pandas>=0.19 in /home/heigatvu/my-project/competition/HCMC-AI/pipeline-hcm-ai/venv/lib/python3.9/site-packages (from pyannote.database>=5.0.1->pyannote.audio) (1.5.0)\n",
      "Requirement already satisfied: typer>=0.12.1 in /home/heigatvu/my-project/competition/HCMC-AI/pipeline-hcm-ai/venv/lib/python3.9/site-packages (from pyannote.database>=5.0.1->pyannote.audio) (0.12.4)\n",
      "Requirement already satisfied: matplotlib>=2.0.0 in /home/heigatvu/my-project/competition/HCMC-AI/pipeline-hcm-ai/venv/lib/python3.9/site-packages (from pyannote.metrics>=3.2->pyannote.audio) (3.6.0)\n",
      "Requirement already satisfied: tabulate>=0.7.7 in /home/heigatvu/my-project/competition/HCMC-AI/pipeline-hcm-ai/venv/lib/python3.9/site-packages (from pyannote.metrics>=3.2->pyannote.audio) (0.9.0)\n",
      "Requirement already satisfied: docopt>=0.6.2 in /home/heigatvu/my-project/competition/HCMC-AI/pipeline-hcm-ai/venv/lib/python3.9/site-packages (from pyannote.metrics>=3.2->pyannote.audio) (0.6.2)\n",
      "Requirement already satisfied: sympy>=1.1 in /home/heigatvu/my-project/competition/HCMC-AI/pipeline-hcm-ai/venv/lib/python3.9/site-packages (from pyannote.metrics>=3.2->pyannote.audio) (1.13.2)\n",
      "Requirement already satisfied: scikit-learn>=0.17.1 in /home/heigatvu/my-project/competition/HCMC-AI/pipeline-hcm-ai/venv/lib/python3.9/site-packages (from pyannote.metrics>=3.2->pyannote.audio) (1.5.1)\n",
      "Requirement already satisfied: optuna>=3.1 in /home/heigatvu/my-project/competition/HCMC-AI/pipeline-hcm-ai/venv/lib/python3.9/site-packages (from pyannote.pipeline>=3.0.1->pyannote.audio) (3.6.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/heigatvu/my-project/competition/HCMC-AI/pipeline-hcm-ai/venv/lib/python3.9/site-packages (from rich>=12.0.0->pyannote.audio) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/heigatvu/my-project/competition/HCMC-AI/pipeline-hcm-ai/venv/lib/python3.9/site-packages (from rich>=12.0.0->pyannote.audio) (2.18.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /home/heigatvu/my-project/competition/HCMC-AI/pipeline-hcm-ai/venv/lib/python3.9/site-packages (from soundfile>=0.12.1->pyannote.audio) (1.17.0)\n",
      "Requirement already satisfied: joblib in /home/heigatvu/my-project/competition/HCMC-AI/pipeline-hcm-ai/venv/lib/python3.9/site-packages (from speechbrain>=1.0.0->pyannote.audio) (1.4.2)\n",
      "Requirement already satisfied: hyperpyyaml in /home/heigatvu/my-project/competition/HCMC-AI/pipeline-hcm-ai/venv/lib/python3.9/site-packages (from speechbrain>=1.0.0->pyannote.audio) (1.2.2)\n",
      "Requirement already satisfied: sentencepiece in /home/heigatvu/my-project/competition/HCMC-AI/pipeline-hcm-ai/venv/lib/python3.9/site-packages (from speechbrain>=1.0.0->pyannote.audio) (0.2.0)\n",
      "Requirement already satisfied: protobuf>=3.20 in /home/heigatvu/my-project/competition/HCMC-AI/pipeline-hcm-ai/venv/lib/python3.9/site-packages (from tensorboardX>=2.6->pyannote.audio) (4.25.4)\n",
      "Requirement already satisfied: triton==2.3.1 in /home/heigatvu/my-project/competition/HCMC-AI/pipeline-hcm-ai/venv/lib/python3.9/site-packages (from torch>=2.0.0->pyannote.audio) (2.3.1)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/heigatvu/my-project/competition/HCMC-AI/pipeline-hcm-ai/venv/lib/python3.9/site-packages (from torch>=2.0.0->pyannote.audio) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/heigatvu/my-project/competition/HCMC-AI/pipeline-hcm-ai/venv/lib/python3.9/site-packages (from torch>=2.0.0->pyannote.audio) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/heigatvu/my-project/competition/HCMC-AI/pipeline-hcm-ai/venv/lib/python3.9/site-packages (from torch>=2.0.0->pyannote.audio) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/heigatvu/my-project/competition/HCMC-AI/pipeline-hcm-ai/venv/lib/python3.9/site-packages (from torch>=2.0.0->pyannote.audio) (12.1.0.106)\n",
      "Requirement already satisfied: networkx in /home/heigatvu/my-project/competition/HCMC-AI/pipeline-hcm-ai/venv/lib/python3.9/site-packages (from torch>=2.0.0->pyannote.audio) (3.2.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/heigatvu/my-project/competition/HCMC-AI/pipeline-hcm-ai/venv/lib/python3.9/site-packages (from torch>=2.0.0->pyannote.audio) (12.1.105)\n",
      "Requirement already satisfied: jinja2 in /home/heigatvu/my-project/competition/HCMC-AI/pipeline-hcm-ai/venv/lib/python3.9/site-packages (from torch>=2.0.0->pyannote.audio) (3.1.4)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/heigatvu/my-project/competition/HCMC-AI/pipeline-hcm-ai/venv/lib/python3.9/site-packages (from torch>=2.0.0->pyannote.audio) (2.20.5)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/heigatvu/my-project/competition/HCMC-AI/pipeline-hcm-ai/venv/lib/python3.9/site-packages (from torch>=2.0.0->pyannote.audio) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/heigatvu/my-project/competition/HCMC-AI/pipeline-hcm-ai/venv/lib/python3.9/site-packages (from torch>=2.0.0->pyannote.audio) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/heigatvu/my-project/competition/HCMC-AI/pipeline-hcm-ai/venv/lib/python3.9/site-packages (from torch>=2.0.0->pyannote.audio) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/heigatvu/my-project/competition/HCMC-AI/pipeline-hcm-ai/venv/lib/python3.9/site-packages (from torch>=2.0.0->pyannote.audio) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/heigatvu/my-project/competition/HCMC-AI/pipeline-hcm-ai/venv/lib/python3.9/site-packages (from torch>=2.0.0->pyannote.audio) (12.1.105)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/heigatvu/my-project/competition/HCMC-AI/pipeline-hcm-ai/venv/lib/python3.9/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.0.0->pyannote.audio) (12.6.20)\n",
      "Requirement already satisfied: julius<0.3,>=0.2.3 in /home/heigatvu/my-project/competition/HCMC-AI/pipeline-hcm-ai/venv/lib/python3.9/site-packages (from torch-audiomentations>=0.11.0->pyannote.audio) (0.2.7)\n",
      "Requirement already satisfied: librosa>=0.6.0 in /home/heigatvu/my-project/competition/HCMC-AI/pipeline-hcm-ai/venv/lib/python3.9/site-packages (from torch-audiomentations>=0.11.0->pyannote.audio) (0.10.2.post1)\n",
      "Requirement already satisfied: torch-pitch-shift>=1.2.2 in /home/heigatvu/my-project/competition/HCMC-AI/pipeline-hcm-ai/venv/lib/python3.9/site-packages (from torch-audiomentations>=0.11.0->pyannote.audio) (1.2.4)\n",
      "Requirement already satisfied: pycparser in /home/heigatvu/my-project/competition/HCMC-AI/pipeline-hcm-ai/venv/lib/python3.9/site-packages (from cffi>=1.0->soundfile>=0.12.1->pyannote.audio) (2.22)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /home/heigatvu/my-project/competition/HCMC-AI/pipeline-hcm-ai/venv/lib/python3.9/site-packages (from fsspec>=2023.5.0->huggingface-hub>=0.13.0->pyannote.audio) (3.10.5)\n",
      "Requirement already satisfied: pooch>=1.1 in /home/heigatvu/my-project/competition/HCMC-AI/pipeline-hcm-ai/venv/lib/python3.9/site-packages (from librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote.audio) (1.8.2)\n",
      "Requirement already satisfied: msgpack>=1.0 in /home/heigatvu/my-project/competition/HCMC-AI/pipeline-hcm-ai/venv/lib/python3.9/site-packages (from librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote.audio) (1.0.8)\n",
      "Requirement already satisfied: soxr>=0.3.2 in /home/heigatvu/my-project/competition/HCMC-AI/pipeline-hcm-ai/venv/lib/python3.9/site-packages (from librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote.audio) (0.4.0)\n",
      "Requirement already satisfied: audioread>=2.1.9 in /home/heigatvu/my-project/competition/HCMC-AI/pipeline-hcm-ai/venv/lib/python3.9/site-packages (from librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote.audio) (3.0.1)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /home/heigatvu/my-project/competition/HCMC-AI/pipeline-hcm-ai/venv/lib/python3.9/site-packages (from librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote.audio) (5.1.1)\n",
      "Requirement already satisfied: lazy-loader>=0.1 in /home/heigatvu/my-project/competition/HCMC-AI/pipeline-hcm-ai/venv/lib/python3.9/site-packages (from librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote.audio) (0.4)\n",
      "Requirement already satisfied: numba>=0.51.0 in /home/heigatvu/my-project/competition/HCMC-AI/pipeline-hcm-ai/venv/lib/python3.9/site-packages (from librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote.audio) (0.60.0)\n",
      "Requirement already satisfied: setuptools in /home/heigatvu/my-project/competition/HCMC-AI/pipeline-hcm-ai/venv/lib/python3.9/site-packages (from lightning-utilities<2.0,>=0.10.0->lightning>=2.0.1->pyannote.audio) (58.1.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/heigatvu/my-project/competition/HCMC-AI/pipeline-hcm-ai/venv/lib/python3.9/site-packages (from markdown-it-py>=2.2.0->rich>=12.0.0->pyannote.audio) (0.1.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/heigatvu/my-project/competition/HCMC-AI/pipeline-hcm-ai/venv/lib/python3.9/site-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (10.4.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/heigatvu/my-project/competition/HCMC-AI/pipeline-hcm-ai/venv/lib/python3.9/site-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (1.4.5)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/heigatvu/my-project/competition/HCMC-AI/pipeline-hcm-ai/venv/lib/python3.9/site-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/heigatvu/my-project/competition/HCMC-AI/pipeline-hcm-ai/venv/lib/python3.9/site-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/heigatvu/my-project/competition/HCMC-AI/pipeline-hcm-ai/venv/lib/python3.9/site-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (4.53.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/heigatvu/my-project/competition/HCMC-AI/pipeline-hcm-ai/venv/lib/python3.9/site-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (2.9.0.post0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /home/heigatvu/my-project/competition/HCMC-AI/pipeline-hcm-ai/venv/lib/python3.9/site-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (3.1.2)\n",
      "Requirement already satisfied: sqlalchemy>=1.3.0 in /home/heigatvu/my-project/competition/HCMC-AI/pipeline-hcm-ai/venv/lib/python3.9/site-packages (from optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio) (2.0.32)\n",
      "Requirement already satisfied: colorlog in /home/heigatvu/my-project/competition/HCMC-AI/pipeline-hcm-ai/venv/lib/python3.9/site-packages (from optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio) (6.8.2)\n",
      "Requirement already satisfied: alembic>=1.5.0 in /home/heigatvu/my-project/competition/HCMC-AI/pipeline-hcm-ai/venv/lib/python3.9/site-packages (from optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio) (1.13.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/heigatvu/my-project/competition/HCMC-AI/pipeline-hcm-ai/venv/lib/python3.9/site-packages (from pandas>=0.19->pyannote.database>=5.0.1->pyannote.audio) (2024.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/heigatvu/my-project/competition/HCMC-AI/pipeline-hcm-ai/venv/lib/python3.9/site-packages (from scikit-learn>=0.17.1->pyannote.metrics>=3.2->pyannote.audio) (3.5.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/heigatvu/my-project/competition/HCMC-AI/pipeline-hcm-ai/venv/lib/python3.9/site-packages (from sympy>=1.1->pyannote.metrics>=3.2->pyannote.audio) (1.3.0)\n",
      "Requirement already satisfied: primePy>=1.3 in /home/heigatvu/my-project/competition/HCMC-AI/pipeline-hcm-ai/venv/lib/python3.9/site-packages (from torch-pitch-shift>=1.2.2->torch-audiomentations>=0.11.0->pyannote.audio) (1.3)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /home/heigatvu/my-project/competition/HCMC-AI/pipeline-hcm-ai/venv/lib/python3.9/site-packages (from typer>=0.12.1->pyannote.database>=5.0.1->pyannote.audio) (1.5.4)\n",
      "Requirement already satisfied: click>=8.0.0 in /home/heigatvu/my-project/competition/HCMC-AI/pipeline-hcm-ai/venv/lib/python3.9/site-packages (from typer>=0.12.1->pyannote.database>=5.0.1->pyannote.audio) (8.1.7)\n",
      "Requirement already satisfied: ruamel.yaml>=0.17.28 in /home/heigatvu/my-project/competition/HCMC-AI/pipeline-hcm-ai/venv/lib/python3.9/site-packages (from hyperpyyaml->speechbrain>=1.0.0->pyannote.audio) (0.18.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/heigatvu/my-project/competition/HCMC-AI/pipeline-hcm-ai/venv/lib/python3.9/site-packages (from jinja2->torch>=2.0.0->pyannote.audio) (2.1.5)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/heigatvu/my-project/competition/HCMC-AI/pipeline-hcm-ai/venv/lib/python3.9/site-packages (from requests->huggingface-hub>=0.13.0->pyannote.audio) (2.10)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/heigatvu/my-project/competition/HCMC-AI/pipeline-hcm-ai/venv/lib/python3.9/site-packages (from requests->huggingface-hub>=0.13.0->pyannote.audio) (3.3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/heigatvu/my-project/competition/HCMC-AI/pipeline-hcm-ai/venv/lib/python3.9/site-packages (from requests->huggingface-hub>=0.13.0->pyannote.audio) (2024.7.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/heigatvu/my-project/competition/HCMC-AI/pipeline-hcm-ai/venv/lib/python3.9/site-packages (from requests->huggingface-hub>=0.13.0->pyannote.audio) (2.2.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/heigatvu/my-project/competition/HCMC-AI/pipeline-hcm-ai/venv/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec>=2023.5.0->huggingface-hub>=0.13.0->pyannote.audio) (1.4.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/heigatvu/my-project/competition/HCMC-AI/pipeline-hcm-ai/venv/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec>=2023.5.0->huggingface-hub>=0.13.0->pyannote.audio) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/heigatvu/my-project/competition/HCMC-AI/pipeline-hcm-ai/venv/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec>=2023.5.0->huggingface-hub>=0.13.0->pyannote.audio) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /home/heigatvu/my-project/competition/HCMC-AI/pipeline-hcm-ai/venv/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec>=2023.5.0->huggingface-hub>=0.13.0->pyannote.audio) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/heigatvu/my-project/competition/HCMC-AI/pipeline-hcm-ai/venv/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec>=2023.5.0->huggingface-hub>=0.13.0->pyannote.audio) (1.9.4)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/heigatvu/my-project/competition/HCMC-AI/pipeline-hcm-ai/venv/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec>=2023.5.0->huggingface-hub>=0.13.0->pyannote.audio) (24.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/heigatvu/my-project/competition/HCMC-AI/pipeline-hcm-ai/venv/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec>=2023.5.0->huggingface-hub>=0.13.0->pyannote.audio) (6.0.5)\n",
      "Requirement already satisfied: Mako in /home/heigatvu/my-project/competition/HCMC-AI/pipeline-hcm-ai/venv/lib/python3.9/site-packages (from alembic>=1.5.0->optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio) (1.3.5)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /home/heigatvu/my-project/competition/HCMC-AI/pipeline-hcm-ai/venv/lib/python3.9/site-packages (from numba>=0.51.0->librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote.audio) (0.43.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /home/heigatvu/my-project/competition/HCMC-AI/pipeline-hcm-ai/venv/lib/python3.9/site-packages (from pooch>=1.1->librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote.audio) (4.2.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/heigatvu/my-project/competition/HCMC-AI/pipeline-hcm-ai/venv/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (1.16.0)\n",
      "Requirement already satisfied: ruamel.yaml.clib>=0.2.7 in /home/heigatvu/my-project/competition/HCMC-AI/pipeline-hcm-ai/venv/lib/python3.9/site-packages (from ruamel.yaml>=0.17.28->hyperpyyaml->speechbrain>=1.0.0->pyannote.audio) (0.2.8)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/heigatvu/my-project/competition/HCMC-AI/pipeline-hcm-ai/venv/lib/python3.9/site-packages (from sqlalchemy>=1.3.0->optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio) (3.0.3)\n",
      "\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! pip install ffmpeg-python\n",
    "! pip install pyannote.audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ffmpeg\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from pyannote.audio import Pipeline\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse data path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_video_info(videos_dir):\n",
    "    \"\"\"Parse video information from the directory structure.\"\"\"\n",
    "    all_video_paths = {}\n",
    "    for part in sorted(os.listdir(videos_dir)):\n",
    "        data_part = part.split('_')[-1]\n",
    "        all_video_paths[data_part] = {}\n",
    "\n",
    "    for data_part in sorted(all_video_paths.keys()):\n",
    "        data_part_path = f'{videos_dir}/Videos_{data_part}/video'\n",
    "        video_paths = sorted(os.listdir(data_part_path))\n",
    "        video_ids = [video_path.replace('.mp4', '').split(\n",
    "            '_')[-1] for video_path in video_paths]\n",
    "        for video_id, video_path in zip(video_ids, video_paths):\n",
    "            video_path_full = f'{data_part_path}/{video_path}'\n",
    "            all_video_paths[data_part][video_id] = video_path_full\n",
    "\n",
    "    return all_video_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VOICE ACTIVITY DETECTION (VAD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_vad_pipeline():\n",
    "    try:\n",
    "        # Retrieve the token from environment or use hardcoded\n",
    "        token = os.getenv(\"HUGGINGFACE_TOKEN\", \"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\")\n",
    "        \n",
    "        # Attempt to load the pipeline\n",
    "        pipeline = Pipeline.from_pretrained(\"pyannote/voice-activity-detection\",\n",
    "                                            use_auth_token=token)\n",
    "        \n",
    "        # Check if the pipeline was loaded successfully\n",
    "        if pipeline is None:\n",
    "            raise ValueError(\"Pipeline returned None. Please check your token and model name.\")\n",
    "        \n",
    "        # Move the pipeline to the appropriate device\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        pipeline = pipeline.to(device)\n",
    "        \n",
    "        return pipeline\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error initializing VAD pipeline: {e}\")\n",
    "        return None\n",
    "\n",
    "def get_video_frame_rate(video_path):\n",
    "    \"\"\"Get the frame rate of the video\"\"\"\n",
    "    \n",
    "    probe = ffmpeg.probe(video_path)\n",
    "    video_streams = [stream for stream in probe['streams'] if stream['codec_type'] == 'video']\n",
    "    if not video_streams:\n",
    "        raise ValueError(\"No video stream found in the file.\")\n",
    "    frame_rate = eval(video_streams[0]['avg_frame_rate'])\n",
    "    return frame_rate\n",
    "    \n",
    "def run_vad_on_audio(pipeline, audio_path):\n",
    "    \"\"\"Run VAD on extracted audio and return the list of speech segments with start and end times\"\"\"\n",
    "    \n",
    "    output = pipeline(audio_path)\n",
    "    speech_segments = []\n",
    "    for speech in output.get_timeline().support():\n",
    "        speech_segments.append((speech.start, speech.end))\n",
    "    return speech_segments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_audio(video_path, output_audio_path):\n",
    "    \"\"\"Extract full audio from video file\"\"\"\n",
    "    \n",
    "    try:\n",
    "        (\n",
    "            ffmpeg\n",
    "            .input(video_path)\n",
    "            .output(output_audio_path)\n",
    "            .run(overwrite_output=True)\n",
    "        )\n",
    "        return output_audio_path\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting audio from {video_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "def process_videos_with_vad(all_video_paths, save_dir_all):\n",
    "    \"\"\"Process each video with VAD and split audio based on speech segments\"\"\"\n",
    "    \n",
    "    vad_pipeline = initialize_vad_pipeline()\n",
    "\n",
    "    if vad_pipeline is None:\n",
    "        print(\"Failed to initialize the VAD pipeline. Please check your configuration.\")\n",
    "        return\n",
    "    \n",
    "    if not os.path.exists(save_dir_all): \n",
    "        os.mkdir(save_dir_all)\n",
    "\n",
    "    for key in all_video_paths.keys():\n",
    "        save_dir = f\"{save_dir_all}/{key}\"\n",
    "        \n",
    "        if not os.path.exists(save_dir):\n",
    "            os.mkdir(save_dir)\n",
    "        \n",
    "        if not all_video_paths[key]:\n",
    "            print(f\"Skipping empty AIC_Video subdirectory: {key}\")\n",
    "            continue\n",
    "        \n",
    "        video_paths_dict = all_video_paths[key]\n",
    "        video_ids = sorted(video_paths_dict.keys())\n",
    "        for video_id in tqdm(video_ids):\n",
    "            video_path = video_paths_dict[video_id]\n",
    "            \n",
    "            # Create a folder for this video_id\n",
    "            video_save_dir = os.path.join(save_dir, video_id)\n",
    "            if not os.path.exists(video_save_dir):\n",
    "                os.mkdir(video_save_dir)\n",
    "\n",
    "            # Extract full audio\n",
    "            full_audio_path = os.path.join(video_save_dir, \"full_audio.wav\")\n",
    "            extract_audio(video_path, full_audio_path)\n",
    "\n",
    "            # Run VAD on full audio\n",
    "            vad_output = vad_pipeline(full_audio_path)\n",
    "\n",
    "            # Get video frame rate\n",
    "            frame_rate = get_video_frame_rate(video_path)\n",
    "\n",
    "            # Process speech segments\n",
    "            speech_segments = []\n",
    "            for speech_turn, _, _ in vad_output.itertracks(yield_label=True):\n",
    "                start_frame = int(speech_turn.start * frame_rate)\n",
    "                end_frame = int(speech_turn.end * frame_rate)\n",
    "                speech_segments.append([start_frame, end_frame])\n",
    "\n",
    "            # Save speech segments as audio files and update JSON\n",
    "            for idx, (start_frame, end_frame) in enumerate(speech_segments):\n",
    "                start_time = start_frame / frame_rate\n",
    "                end_time = end_frame / frame_rate\n",
    "                \n",
    "                segment_audio_path = os.path.join(video_save_dir, f\"{str(idx+1).zfill(5)}.mp3\")\n",
    "                \n",
    "                # Extract and save the speech segment\n",
    "                (\n",
    "                    ffmpeg\n",
    "                    .input(full_audio_path, ss=start_time, to=end_time)\n",
    "                    .output(segment_audio_path)\n",
    "                    .run(overwrite_output=True)\n",
    "                )\n",
    "\n",
    "            # Save frame ranges to JSON\n",
    "            json_path = os.path.join(video_save_dir, f\"{video_id}_speech_frames.json\")\n",
    "            with open(json_path, 'w') as f:\n",
    "                json.dump(speech_segments, f)\n",
    "\n",
    "            # Remove the full audio file\n",
    "            os.remove(full_audio_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.1.3 to v2.4.0. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../../../../../../../.cache/torch/pyannote/models--pyannote--segmentation/snapshots/059e96f964841d40f1a5e755bb7223f76666bba4/pytorch_model.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.3.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.7.1, yours is 2.3.1+cu121. Bad things might happen unless you revert torch to 1.x.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]ffmpeg version 6.1.1-3ubuntu5+esm1 Copyright (c) 2000-2023 the FFmpeg developers\n",
      "  built with gcc 13 (Ubuntu 13.2.0-23ubuntu4)\n",
      "  configuration: --prefix=/usr --extra-version=3ubuntu5+esm1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --disable-omx --enable-gnutls --enable-libaom --enable-libass --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libglslang --enable-libgme --enable-libgsm --enable-libharfbuzz --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-openal --enable-opencl --enable-opengl --disable-sndio --enable-libvpl --disable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-ladspa --enable-libbluray --enable-libjack --enable-libpulse --enable-librabbitmq --enable-librist --enable-libsrt --enable-libssh --enable-libsvtav1 --enable-libx264 --enable-libzmq --enable-libzvbi --enable-lv2 --enable-sdl2 --enable-libplacebo --enable-librav1e --enable-pocketsphinx --enable-librsvg --enable-libjxl --enable-shared\n",
      "  libavutil      58. 29.100 / 58. 29.100\n",
      "  libavcodec     60. 31.102 / 60. 31.102\n",
      "  libavformat    60. 16.100 / 60. 16.100\n",
      "  libavdevice    60.  3.100 / 60.  3.100\n",
      "  libavfilter     9. 12.100 /  9. 12.100\n",
      "  libswscale      7.  5.100 /  7.  5.100\n",
      "  libswresample   4. 12.100 /  4. 12.100\n",
      "  libpostproc    57.  3.100 / 57.  3.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from '/home/heigatvu/my-project/competition/HCMC-AI/pipeline-hcm-ai/notebooks/data_extraction/dataset/AIC_Video/Videos_L01/video/L01_V001.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : dash\n",
      "    minor_version   : 0\n",
      "    compatible_brands: iso6avc1mp41\n",
      "    creation_time   : 2023-11-01T17:39:12.000000Z\n",
      "  Duration: 00:21:06.60, start: 0.000000, bitrate: 584 kb/s\n",
      "  Stream #0:0[0x1](und): Video: h264 (Main) (avc1 / 0x31637661), yuv420p(tv, bt709, progressive), 1280x720 [SAR 1:1 DAR 16:9], 3 kb/s, 25 fps, 25 tbr, 12800 tbn (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2023-11-01T17:39:12.000000Z\n",
      "      handler_name    : ISO Media file produced by Google Inc.\n",
      "      vendor_id       : [0][0][0][0]\n",
      "Output #0, wav, to '/home/heigatvu/my-project/competition/HCMC-AI/pipeline-hcm-ai/notebooks/data_extraction/audio/Audio/L01/V001/full_audio.wav':\n",
      "[out#0/wav @ 0x64dd357f3f00] Output file does not contain any stream\n",
      "Error opening output file /home/heigatvu/my-project/competition/HCMC-AI/pipeline-hcm-ai/notebooks/data_extraction/audio/Audio/L01/V001/full_audio.wav.\n",
      "Error opening output files: Invalid argument\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error extracting audio from /home/heigatvu/my-project/competition/HCMC-AI/pipeline-hcm-ai/notebooks/data_extraction/dataset/AIC_Video/Videos_L01/video/L01_V001.mp4: ffmpeg error (see stderr output for detail)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "File /home/heigatvu/my-project/competition/HCMC-AI/pipeline-hcm-ai/notebooks/data_extraction/audio/Audio/L01/V001/full_audio.wav does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m all_video_paths \u001b[38;5;241m=\u001b[39m parse_video_info(videos_dir)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mprocess_videos_with_vad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_video_paths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_dir_all\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[27], line 53\u001b[0m, in \u001b[0;36mprocess_videos_with_vad\u001b[0;34m(all_video_paths, save_dir_all)\u001b[0m\n\u001b[1;32m     50\u001b[0m extract_audio(video_path, full_audio_path)\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# Run VAD on full audio\u001b[39;00m\n\u001b[0;32m---> 53\u001b[0m vad_output \u001b[38;5;241m=\u001b[39m \u001b[43mvad_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfull_audio_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# Get video frame rate\u001b[39;00m\n\u001b[1;32m     56\u001b[0m frame_rate \u001b[38;5;241m=\u001b[39m get_video_frame_rate(video_path)\n",
      "File \u001b[0;32m~/my-project/competition/HCMC-AI/pipeline-hcm-ai/venv/lib/python3.9/site-packages/pyannote/audio/core/pipeline.py:321\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[0;34m(self, file, **kwargs)\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    313\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA pipeline must be instantiated with `pipeline.instantiate(paramaters)` before it can be applied. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    314\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTried to use parameters provided by `pipeline.default_parameters()` but those are not compatible. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    315\u001b[0m         )\n\u001b[1;32m    317\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    318\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe pipeline has been automatically instantiated with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdefault_parameters\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    319\u001b[0m     )\n\u001b[0;32m--> 321\u001b[0m file \u001b[38;5;241m=\u001b[39m \u001b[43mAudio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    323\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpreprocessors\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    324\u001b[0m     file \u001b[38;5;241m=\u001b[39m ProtocolFile(file, lazy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocessors)\n",
      "File \u001b[0;32m~/my-project/competition/HCMC-AI/pipeline-hcm-ai/venv/lib/python3.9/site-packages/pyannote/audio/core/io.py:194\u001b[0m, in \u001b[0;36mAudio.validate_file\u001b[0;34m(file)\u001b[0m\n\u001b[1;32m    192\u001b[0m     path \u001b[38;5;241m=\u001b[39m Path(file[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maudio\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    193\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m path\u001b[38;5;241m.\u001b[39mis_file():\n\u001b[0;32m--> 194\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not exist\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    196\u001b[0m     file\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muri\u001b[39m\u001b[38;5;124m\"\u001b[39m, path\u001b[38;5;241m.\u001b[39mstem)\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: File /home/heigatvu/my-project/competition/HCMC-AI/pipeline-hcm-ai/notebooks/data_extraction/audio/Audio/L01/V001/full_audio.wav does not exist"
     ]
    }
   ],
   "source": [
    "all_video_paths = parse_video_info(videos_dir)\n",
    "process_videos_with_vad(all_video_paths, save_dir_all)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
