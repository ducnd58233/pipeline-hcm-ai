{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "videos_dir = None\n",
    "save_dir = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "dir_path = os.getcwd()\n",
    "\n",
    "if not videos_dir:\n",
    "    if 'google.colab' in str(get_ipython()):\n",
    "        # Update this path as necessary\n",
    "        videos_dir = f'{dir_path}/AIC_Video'\n",
    "    elif 'kaggle' in str(get_ipython()):\n",
    "        videos_dir = f'{dir_path}/AIC_Video'\n",
    "    else:\n",
    "        parent_dir_path = os.path.dirname(dir_path)\n",
    "        videos_dir = f'{parent_dir_path}/dataset/AIC_Video'\n",
    "        \n",
    "if not save_dir:\n",
    "    save_dir = f'{dir_path}/SceneJSON'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'TransNetV2' already exists and is not an empty directory.\n",
      "Updated Git hooks.\n",
      "Git LFS initialized.\n",
      "fetch: Fetching reference refs/heads/feature/audio\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/soCzech/TransNetV2.git\n",
    "!git lfs install\n",
    "!cd TransNetV2\n",
    "!git lfs fetch https://github.com/soCzech/TransNetV2.git\n",
    "!git lfs checkout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-21 22:20:17.191978: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-08-21 22:20:17.215479: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-08-21 22:20:17.405128: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-21 22:20:18.259886: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# Import module\n",
    "import os\n",
    "import cv2\n",
    "import json\n",
    "import glob\n",
    "import ffmpeg\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from TransNetV2.inference.transnetv2 import TransNetV2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse video info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_video_info(videos_dir):\n",
    "    \"\"\"Parse video information from the directory structure.\"\"\"\n",
    "    all_video_paths = {}\n",
    "    for part in sorted(os.listdir(videos_dir)):\n",
    "        data_part = part.split('_')[-1]  # define specific name (L21, L22) in each name dir (Videos_L21, L22 ...) of dataset\n",
    "        all_video_paths[data_part] = {} # add specific name as key and create list as value\n",
    "\n",
    "    for data_part in sorted(all_video_paths.keys()):\n",
    "        data_part_path = f'{videos_dir}/Videos_{data_part}/video' # Define dir of Videos_L21/Video,...\n",
    "        video_paths = sorted(os.listdir(data_part_path)) # Create list item in dir above\n",
    "        video_ids = [video_path.replace('.mp4', '').split('_')[-1] for video_path in video_paths] # extract code name of video (V001, V002,...)\n",
    "        for video_id, video_path in zip(video_ids, video_paths):\n",
    "            video_path_full = f'{data_part_path}/{video_path}' \n",
    "            all_video_paths[data_part][video_id] = video_path_full #Save dict {\"L21\": {\"V001\": \"video path\"}}\n",
    "\n",
    "    return all_video_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_video_paths = {}\n",
    "for part in sorted(os.listdir(videos_dir)):\n",
    "    data_part = part.split('_')[-1]  # define specific name (L21, L22) in each name dir (Videos_L21, L22 ...) of dataset\n",
    "    all_video_paths[data_part] = {} # add specific name as key and create list as value\n",
    "\n",
    "for data_part in sorted(all_video_paths.keys()):\n",
    "    data_part_path = f'{videos_dir}/Videos_{data_part}/video' # Define dir of Videos_L21/Video,...\n",
    "    video_paths = sorted(os.listdir(data_part_path)) # Create list item in dir above\n",
    "    video_ids = [video_path.replace('.mp4', '').split('_')[-1] for video_path in video_paths] # extract code name of video (V001, V002,...)\n",
    "    for video_id, video_path in zip(video_ids, video_paths):\n",
    "        video_path_full = f'{data_part_path}/{video_path}' \n",
    "        all_video_paths[data_part][video_id] = video_path_full #Save dict {\"L21\": {\"V001\": \"video path\"}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_directory(path):\n",
    "    \"\"\"Create a directory if it does not exist.\"\"\"\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "def predict_scenes_and_save(model, all_video_paths, save_dir):\n",
    "    \"\"\"Predict scenes for each video and save the results as JSON files.\"\"\"\n",
    "    create_directory(save_dir)\n",
    "\n",
    "    for key, video_paths_dict in tqdm(all_video_paths.items()):\n",
    "        video_ids = sorted(video_paths_dict.keys()) # Take video name (L21, L22,...)\n",
    "        key_dir = os.path.join(save_dir, key) # Connect path ./transnet/SceneJSON/L21,....\n",
    "        create_directory(key_dir) # Create dir following key_dir\n",
    "\n",
    "        for video_id in tqdm(video_ids, desc=f\"Processing {key}\"):\n",
    "            video_path = video_paths_dict[video_id]\n",
    "            _, single_frame_predictions, _ = model.predict_video(video_path)\n",
    "\n",
    "            # Generate list of scenes from predictions, returns tuples of (start frame, end frame)\n",
    "            scenes = model.predictions_to_scenes(single_frame_predictions)\n",
    "\n",
    "            with open(os.path.join(key_dir, f\"{video_id}.json\"), 'w') as f:\n",
    "                json.dump(scenes.tolist(), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TransNetV2] Using weights from /home/heigatvu/my-project/competition/HCMC-AI/pipeline-hcm-ai/notebooks/data_extraction/transnet/TransNetV2/inference/transnetv2-weights/.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-21 22:20:19.762932: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-08-21 22:20:19.763462: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1956] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TransNetV2] Extracting frames from /home/heigatvu/my-project/competition/HCMC-AI/pipeline-hcm-ai/notebooks/data_extraction/dataset/AIC_Video/Videos_L01/video/L01_V001.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-21 22:20:37.906790: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [1,100,27,48,3]\n",
      "\t [[{{node inputs}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TransNetV2] Processing video frames 31650/31665"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TransNetV2] Processing video frames 31665/31665\n",
      "[TransNetV2] Extracting frames from /home/heigatvu/my-project/competition/HCMC-AI/pipeline-hcm-ai/notebooks/data_extraction/dataset/AIC_Video/Videos_L01/video/L01_V002.mp4\n",
      "[TransNetV2] Processing video frames 24300/24337"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TransNetV2] Processing video frames 24337/24337\n",
      "[TransNetV2] Extracting frames from /home/heigatvu/my-project/competition/HCMC-AI/pipeline-hcm-ai/notebooks/data_extraction/dataset/AIC_Video/Videos_L01/video/L01_V003.mp4\n",
      "[TransNetV2] Processing video frames 30650/30668"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing L01: 100%|██████████| 3/3 [05:46<00:00, 115.41s/it]\n",
      "100%|██████████| 1/1 [05:46<00:00, 346.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TransNetV2] Processing video frames 30668/30668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Must install ffmpeg, sudo apt-get install ffmpeg\n",
    "\n",
    "model = TransNetV2()\n",
    "all_video_paths = parse_video_info(videos_dir)\n",
    "predict_scenes_and_save(model, all_video_paths, save_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
