{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "videos_dir = None\n",
    "scene_json_dirs = None\n",
    "save_dir_all = None\n",
    "# Change this to the desired number of frames per segment\n",
    "num_frames_per_segment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "dir_path = os.getcwd()\n",
    "\n",
    "\n",
    "if not videos_dir:\n",
    "    if 'google.colab' in str(get_ipython()):\n",
    "        # Update this path as necessary\n",
    "        videos_dir = f'{dir_path}/AIC_Video'\n",
    "    elif 'kaggle' in str(get_ipython()):\n",
    "        videos_dir = f'{dir_path}/AIC_Video'\n",
    "    else:\n",
    "        parent_dir_path = os.path.dirname(dir_path)\n",
    "        videos_dir = f'{parent_dir_path}/dataset/AIC_Video'\n",
    "    \n",
    "if not scene_json_dirs:\n",
    "    scene_json_dirs = f'{dir_path}/SceneJSON'\n",
    "    \n",
    "if not save_dir_all:\n",
    "    save_dir_all = f'{dir_path}/Keyframes'\n",
    "    \n",
    "if not num_frames_per_segment:\n",
    "    num_frames_per_segment = 5  # Change this to the desired number of frames per segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'TransNetV2' already exists and is not an empty directory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated Git hooks.\n",
      "Git LFS initialized.\n",
      "fetch: Fetching reference refs/heads/feat/metadata\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/soCzech/TransNetV2.git\n",
    "!git lfs install\n",
    "!cd TransNetV2\n",
    "!git lfs fetch https://github.com/soCzech/TransNetV2.git\n",
    "!git lfs checkout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-28 12:35:38.861313: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-28 12:35:39.050740: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-28 12:35:40.076194: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# Import module\n",
    "import os\n",
    "import cv2\n",
    "import json\n",
    "import glob\n",
    "import ffmpeg\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from TransNetV2.inference.transnetv2 import TransNetV2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process cutting frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_video_info(videos_dir):\n",
    "    \"\"\"Parse video information from the directory structure.\"\"\"\n",
    "    all_video_paths = {}\n",
    "    for part in sorted(os.listdir(videos_dir)):\n",
    "        data_part = part.split('_')[-1]\n",
    "        all_video_paths[data_part] = {}\n",
    "\n",
    "    for data_part in sorted(all_video_paths.keys()):\n",
    "        data_part_path = f'{videos_dir}/Videos_{data_part}/video'\n",
    "        video_paths = sorted(os.listdir(data_part_path))\n",
    "        video_ids = [video_path.replace('.mp4', '').split(\n",
    "            '_')[-1] for video_path in video_paths]\n",
    "        for video_id, video_path in zip(video_ids, video_paths):\n",
    "            video_path_full = f'{data_part_path}/{video_path}'\n",
    "            all_video_paths[data_part][video_id] = video_path_full\n",
    "\n",
    "    return all_video_paths\n",
    "\n",
    "\n",
    "def get_evenly_spaced_frames(start_idx, end_idx, num_frames):\n",
    "    \"\"\"Get evenly spaced frame indices between start_idx and end_idx.\"\"\"\n",
    "    return np.linspace(start_idx, end_idx, num_frames).astype(int)\n",
    "\n",
    "\n",
    "def sample_frames(video_path, scene_json_path, save_dir, num_frames_per_segment, width=48, height=27):\n",
    "    \"\"\"Sample frames from video segments and save them to the specified directory.\"\"\"\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "\n",
    "    with open(scene_json_path, 'r') as f:\n",
    "        video_scenes = json.load(f)\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    for i, shot in enumerate(tqdm(video_scenes)):\n",
    "        shot_frames_id = get_evenly_spaced_frames(\n",
    "            shot[0], shot[1], num_frames_per_segment)\n",
    "        for index in shot_frames_id:\n",
    "            cap.set(cv2.CAP_PROP_POS_FRAMES, index)\n",
    "            ret, frame = cap.read()\n",
    "            if ret:\n",
    "                frame = cv2.resize(frame, (width, height))\n",
    "                filename = f\"{save_dir}/{index:06d}.jpg\"\n",
    "                if not cv2.imwrite(filename, frame):\n",
    "                    print('Failed to save frame:', filename)\n",
    "            else:\n",
    "                print('Failed to read frame at index:', index)\n",
    "    cap.release()\n",
    "\n",
    "\n",
    "def process_videos(all_video_paths, scene_json_dirs, save_dir_all, num_frames_per_segment):\n",
    "    \"\"\"Process all videos and sample frames from their scenes.\"\"\"\n",
    "    if not os.path.exists(save_dir_all):\n",
    "        os.mkdir(save_dir_all)\n",
    "\n",
    "    for key in all_video_paths.keys():\n",
    "        save_dir = f'{save_dir_all}/{key}_extra'\n",
    "\n",
    "        if not os.path.exists(save_dir):\n",
    "            os.mkdir(save_dir)\n",
    "\n",
    "        video_paths_dict = all_video_paths[key]\n",
    "        video_ids = sorted(video_paths_dict.keys())\n",
    "        for video_id in tqdm(video_ids):\n",
    "            video_path = video_paths_dict[video_id]\n",
    "            video_scene_path = f'{scene_json_dirs}/{key}/{video_id}.json'\n",
    "\n",
    "            save_dir_video = f'{save_dir}/{video_id}'\n",
    "            sample_frames(video_path, video_scene_path,\n",
    "                          save_dir_video, num_frames_per_segment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 269/269 [01:45<00:00,  2.54it/s]\n",
      "100%|██████████| 1/1 [01:45<00:00, 105.74s/it]\n",
      "  0%|          | 0/30 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/jiggle/personal/competition/hcm-ai/Pipeline_HCM_AI/notebooks/data_extraction/transnet/SceneJSON/L21/V001.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m num_frames_per_segment \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m  \u001b[38;5;66;03m# Change this to the desired number of frames per segment\u001b[39;00m\n\u001b[1;32m      6\u001b[0m all_video_paths \u001b[38;5;241m=\u001b[39m parse_video_info(videos_dir)\n\u001b[0;32m----> 7\u001b[0m \u001b[43mprocess_videos\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_video_paths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscene_json_dirs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_dir_all\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_frames_per_segment\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[4], line 68\u001b[0m, in \u001b[0;36mprocess_videos\u001b[0;34m(all_video_paths, scene_json_dirs, save_dir_all, num_frames_per_segment)\u001b[0m\n\u001b[1;32m     65\u001b[0m video_scene_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscene_json_dirs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvideo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.json\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     67\u001b[0m save_dir_video \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msave_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvideo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 68\u001b[0m \u001b[43msample_frames\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvideo_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvideo_scene_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m              \u001b[49m\u001b[43msave_dir_video\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_frames_per_segment\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[4], line 30\u001b[0m, in \u001b[0;36msample_frames\u001b[0;34m(video_path, scene_json_path, save_dir, num_frames_per_segment, width, height)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(save_dir):\n\u001b[1;32m     28\u001b[0m     os\u001b[38;5;241m.\u001b[39mmakedirs(save_dir)\n\u001b[0;32m---> 30\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mscene_json_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     31\u001b[0m     video_scenes \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[1;32m     33\u001b[0m cap \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mVideoCapture(video_path)\n",
      "File \u001b[0;32m~/personal/competition/hcm-ai/Pipeline_HCM_AI/venv/lib/python3.9/site-packages/IPython/core/interactiveshell.py:310\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    304\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    305\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    306\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    307\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    308\u001b[0m     )\n\u001b[0;32m--> 310\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/jiggle/personal/competition/hcm-ai/Pipeline_HCM_AI/notebooks/data_extraction/transnet/SceneJSON/L21/V001.json'"
     ]
    }
   ],
   "source": [
    "all_video_paths = parse_video_info(videos_dir)\n",
    "process_videos(all_video_paths, scene_json_dirs, save_dir_all, num_frames_per_segment)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
