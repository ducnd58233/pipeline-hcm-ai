{"cells":[{"cell_type":"markdown","metadata":{"id":"GulHraT6zQOo"},"source":["# Setup"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p05_qV8PzQOs","tags":["parameters"]},"outputs":[],"source":["# Parameters\n","bs = None\n","keyframes_dir = None\n","save_dir = None"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZtiQ-oOJzQOu"},"outputs":[],"source":["import os\n","\n","dir_path = os.getcwd()\n","\n","if not keyframes_dir:\n","    if 'google.colab' in str(get_ipython()):\n","        # Update this path as necessary\n","        keyframes_dir = f'{dir_path}/keyframes'\n","    elif 'kaggle' in str(get_ipython()):\n","        keyframes_dir = f'{dir_path}/keyframes'\n","    else:\n","        parent_dir_path = os.path.dirname(dir_path)\n","        keyframes_dir = f'{parent_dir_path}/transnet/keyframes'\n","\n","if not bs:\n","    bs = 16\n","\n","if not save_dir:\n","    save_dir = './ocr'"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3757,"status":"ok","timestamp":1725351301283,"user":{"displayName":"HAI NGUYEN","userId":"17697326154185790305"},"user_tz":-420},"id":"X2r2dhXozQOu","outputId":"a34a7806-081c-4dec-f7b1-09d0232006f2"},"outputs":[],"source":["! pip install aiohttp\n","! pip install aiofiles\n","! pip install git+https://github.com/JaidedAI/EasyOCR.git\n","! pip install transformers"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s3HNZbQozQOv"},"outputs":[],"source":["import os\n","import json\n","import asyncio\n","import glob\n","from tqdm import tqdm\n","import easyocr\n","import aiofiles\n","import torch\n","from transformers import AutoTokenizer, AutoModelForSeq2SeqLM"]},{"cell_type":"markdown","metadata":{"id":"UIGU1OA2zQOw"},"source":["# Parse data path"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Oty11jBtzQOw"},"outputs":[],"source":["def parse_keyframe_info(keyframes_dir):\n","    all_keyframe_paths = {}\n","    for part in sorted(os.listdir(keyframes_dir)):\n","        data_part_path = f'{keyframes_dir}/{part}'\n","        data_part = part.split('/')[-1]\n","        all_keyframe_paths[data_part] = []\n","        image_path = sorted(glob.glob(f'{data_part_path}/*.jpg'))\n","        all_keyframe_paths[data_part] = image_path\n","    return all_keyframe_paths"]},{"cell_type":"markdown","metadata":{"id":"JmQSgBZSzQOw"},"source":["# Inference"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":701,"status":"ok","timestamp":1725351996494,"user":{"displayName":"HAI NGUYEN","userId":"17697326154185790305"},"user_tz":-420},"id":"SzvPsEffzQOw"},"outputs":[],"source":["async def create_directory(directory):\n","    \"\"\"Create a directory asynchronously if it doesn't exist.\"\"\"\n","    os.makedirs(directory, exist_ok=True)\n","\n","async def save_ocr_results(save_dir, key, video_ocr_results):\n","    \"\"\"Save OCR results to a JSON file.\"\"\"\n","    filename = f\"{save_dir}/{key}.json\"\n","    async with aiofiles.open(filename, 'w') as f:\n","        await f.write(json.dumps(video_ocr_results, ensure_ascii=False, indent=2))\n","\n","async def ocr_and_save_results(reader, tokenizer, model, device, all_keyframe_paths, save_dir, batch_size=16):\n","    \"\"\"Perform OCR on keyframes, translate, and save results to JSON files.\"\"\"\n","    await create_directory(save_dir)\n","\n","async def translate_text(text, tokenizer, model, device):\n","    \"\"\"Translate text using VinAI's translation model.\"\"\"\n","    input_ids = tokenizer(text, return_tensors=\"pt\").input_ids.to(device)\n","    output_ids = model.generate(\n","        input_ids,\n","        decoder_start_token_id=tokenizer.lang_code_to_id[\"en_XX\"],\n","        num_return_sequences=1,\n","        num_beams=5,\n","        early_stopping=True\n","    )\n","    translated_text = tokenizer.batch_decode(output_ids, skip_special_tokens=True)[0]\n","    return translated_text\n","\n","async def process_image(reader, image_path):\n","    \"\"\"Process a single image with OCR.\"\"\"\n","    result = await asyncio.to_thread(reader.readtext, image_path)\n","    refined_result = [item for item in result if item[2] > 0.5]\n","    refined_result = easyocr.utils.get_paragraph(refined_result)\n","    return [item[1] for item in refined_result]\n","\n","async def process_video_keyframes(reader, tokenizer, model, device, video_keyframe_paths, batch_size=16):\n","    \"\"\"Process keyframes of a video and perform OCR and translation.\"\"\"\n","    video_ocr_results = {}\n","    tasks = []\n","\n","    for i in range(0, len(video_keyframe_paths), batch_size):\n","        batch = video_keyframe_paths[i:i+batch_size]\n","        for image_path in batch:\n","            task = asyncio.create_task(process_image(reader, image_path))\n","            tasks.append((os.path.basename(image_path), task))\n","\n","    for frame_name, task in tasks:\n","        text_detected = await task\n","        if text_detected:\n","            joined_text = \" ||| \".join(text_detected)\n","            translated_text = await translate_text(joined_text, tokenizer, model, device)\n","            translated_items = translated_text.split(\" ||| \")\n","            video_ocr_results[frame_name] = translated_items\n","\n","    return video_ocr_results\n","\n","async def ocr_and_save_results(reader, tokenizer, model, device, all_keyframe_paths, save_dir, batch_size=16):\n","    \"\"\"Perform OCR on keyframes, translate, and save results to JSON files.\"\"\"\n","    await create_directory(save_dir)\n","    keys = sorted(all_keyframe_paths.keys())\n","\n","    for key in tqdm(keys, desc=\"Processing keys\"):\n","        video_keyframe_paths = all_keyframe_paths[key]\n","        video_ocr_results = await process_video_keyframes(\n","            reader, tokenizer, model, device, video_keyframe_paths, batch_size)\n","        await save_ocr_results(save_dir, key, video_ocr_results)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":791163,"status":"ok","timestamp":1725352795515,"user":{"displayName":"HAI NGUYEN","userId":"17697326154185790305"},"user_tz":-420},"id":"TCJ-Geh1zQOw","outputId":"9415e6d1-b733-4b70-a98f-2ff330de0cff"},"outputs":[],"source":["# Main execution\n","all_keyframe_paths = parse_keyframe_info(keyframes_dir)\n","reader = easyocr.Reader(['vi'], gpu=True)\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","tokenizer = AutoTokenizer.from_pretrained(\"vinai/vinai-translate-vi2en-v2\", src_lang=\"vi_VN\")\n","model = AutoModelForSeq2SeqLM.from_pretrained(\"vinai/vinai-translate-vi2en-v2\").to(device)\n","\n","await ocr_and_save_results(reader, tokenizer, model, device, all_keyframe_paths, save_dir, bs)"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"python3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.3"}},"nbformat":4,"nbformat_minor":0}
