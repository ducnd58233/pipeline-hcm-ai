{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Keyframe metadata\n",
    "combined_keyframes_metadata_filename = None\n",
    "keyframes_metadata_dir = None\n",
    "\n",
    "# Object extraction metadata\n",
    "combined_object_extraction_filename = None\n",
    "object_extraction_dir = None\n",
    "\n",
    "# OCR metadata\n",
    "combined_ocr_metadata_filename = None\n",
    "ocr_metadata_dir = None\n",
    "\n",
    "# Tag metadata\n",
    "combined_tag_metadata_filename = None\n",
    "tag_metadata_dir = None\n",
    "\n",
    "# Audio metadata\n",
    "combined_audio_metadata_filename = None\n",
    "audio_metadata_dir = None\n",
    "\n",
    "# # Final metadata\n",
    "# final_metadata_filename = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "dir_path = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_extraction_path = f'{dir_path}/data_extraction'\n",
    "dataset_path = f'{data_extraction_path}/dataset/AIC_Video'\n",
    "\n",
    "# Keyframe metadata\n",
    "if not combined_keyframes_metadata_filename:\n",
    "    combined_keyframes_metadata_filename = 'keyframes_metadata.json'\n",
    "    \n",
    "if not keyframes_metadata_dir:\n",
    "    keyframes_metadata_dir = f'{data_extraction_path}/transnet/keyframes_metadata'\n",
    "    \n",
    "# Object extraction metadata\n",
    "if not combined_object_extraction_filename:\n",
    "    combined_object_extraction_filename = 'object_extraction_metadata.json'\n",
    "    \n",
    "if not object_extraction_dir:\n",
    "    object_extraction_dir = f'{data_extraction_path}/metadata/object_extraction/object_detection'\n",
    "    \n",
    "# OCR metadata\n",
    "if not combined_ocr_metadata_filename:\n",
    "    combined_ocr_metadata_filename = 'ocr_metadata.json'\n",
    "    \n",
    "if not ocr_metadata_dir:\n",
    "    ocr_metadata_dir = f'{data_extraction_path}/metadata/ocr'\n",
    "    \n",
    "# Tag metadata\n",
    "if not combined_tag_metadata_filename:\n",
    "    combined_tag_metadata_filename = 'tag_metadata.json'\n",
    "    \n",
    "if not tag_metadata_dir:\n",
    "    tag_metadata_dir = f'{data_extraction_path}/metadata/tag_output'\n",
    "    \n",
    "# Audio metadata\n",
    "if not combined_audio_metadata_filename:\n",
    "    combined_audio_metadata_filename = 'audio_metadata.json'\n",
    "    \n",
    "if not audio_metadata_dir:\n",
    "    audio_metadata_dir = f'{data_extraction_path}/audio/audio_recognition'\n",
    "    \n",
    "# # final_metadata\n",
    "# if not final_metadata_filename:\n",
    "#     final_metadata_filename = 'final_metadata.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine keyframe metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined keyframe metadata successful: keyframes_metadata.json\n"
     ]
    }
   ],
   "source": [
    "def combine_keyframe_metadata_json_files(directory, output_file):\n",
    "    combined_data = {}\n",
    "\n",
    "    if os.path.exists(output_file):\n",
    "        with open(output_file, 'r') as existing_file:\n",
    "            combined_data = json.load(existing_file)\n",
    "\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith('.json'):\n",
    "            file_path = os.path.join(directory, filename)\n",
    "            \n",
    "            with open(file_path, 'r') as file:\n",
    "                data = json.load(file)\n",
    "        change_key_data = {}\n",
    "        for keyframes_key in data.keys():\n",
    "            if keyframes_key.split(\"_\")[-1] == \"extra\":\n",
    "                change_key_data[f\"{keyframes_key.split('_')[0]}_{keyframes_key.split('_')[1]}_{keyframes_key.split('_')[-1]}_{keyframes_key.split('_')[2]}\"]= data[keyframes_key]\n",
    "            else:\n",
    "                change_key_data[keyframes_key] = data[keyframes_key]\n",
    "\n",
    "        combined_data.update(change_key_data)\n",
    "        keys = list(combined_data.keys())\n",
    "        keys.sort()\n",
    "        sorted_combined_data = {i : combined_data[i] for i in keys}\n",
    "    with open(output_file, 'w') as outfile:\n",
    "        json.dump(sorted_combined_data, outfile)\n",
    "    \n",
    "    print(f'Combined keyframe metadata successful: {output_file}')\n",
    "    \n",
    "\n",
    "combine_keyframe_metadata_json_files(keyframes_metadata_dir, combined_keyframes_metadata_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine object extraction metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined object detection metadata successful: object_extraction_metadata.json\n"
     ]
    }
   ],
   "source": [
    "def preprocess_object_detection(data):\n",
    "    organized_data = {'objects': dict(), 'counts': dict()}\n",
    "    for item in data:\n",
    "        label = item['label']\n",
    "        if label not in organized_data['objects']:\n",
    "            organized_data['objects'][label] = []\n",
    "            organized_data['counts'][label] = 0\n",
    "        organized_data['objects'][label].append({\n",
    "            \"score\": item['score'],\n",
    "            \"box\": item['box']\n",
    "        })\n",
    "        organized_data['counts'][label] += 1\n",
    "\n",
    "    return organized_data\n",
    "\n",
    "def combine_object_extraction_metadata_json_files(directory, output_file):\n",
    "    combined_data = {}\n",
    "\n",
    "    for root, _, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith('_detection.json'):\n",
    "                file_path = os.path.join(root, file)\n",
    "\n",
    "                parts = root.split(os.sep)\n",
    "                video_name = parts[-1]  # L01_V001, L01_V002, etc.\n",
    "                frame_id = file.split('_')[0]  # 000139, etc.\n",
    "                key = f\"{video_name}_{frame_id}_detection\"\n",
    "\n",
    "                with open(file_path, 'r') as f:\n",
    "                    data = json.load(f)\n",
    "\n",
    "                combined_data[key] = preprocess_object_detection(\n",
    "                    data)\n",
    "    keys = list(combined_data.keys())\n",
    "    keys.sort()\n",
    "    sorted_combined_data = {i : combined_data[i] for i in keys}\n",
    "    with open(output_file, 'w') as f:\n",
    "        json.dump(sorted_combined_data, f)\n",
    "\n",
    "    print(f'Combined object detection metadata successful: {output_file}')\n",
    "    \n",
    "\n",
    "combine_object_extraction_metadata_json_files(object_extraction_dir, combined_object_extraction_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined multi tag metadata successful: ocr_metadata.json\n"
     ]
    }
   ],
   "source": [
    "def combine_ocr_metadata_json_file(directory, output_file):\n",
    "    combined_data = {}\n",
    "    if os.path.exists(output_file):\n",
    "        with open(output_file, 'r') as existing_file:\n",
    "            combined_data = json.load(existing_file)\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith('.json'):\n",
    "            file_path = os.path.join(directory, filename)\n",
    "\n",
    "        with open(file_path, 'r') as file:\n",
    "                data = json.load(file)\n",
    "        for key, item in data.items():\n",
    "            combined_data[f\"{filename.split('.')[0]}_{key.split('.')[0]}_ocr\"] = item\n",
    "    keys = list(combined_data.keys())\n",
    "    keys.sort()\n",
    "    sorted_combined_data = {i : combined_data[i] for i in keys}\n",
    "    with open(output_file, 'w') as outfile:\n",
    "        json.dump(sorted_combined_data, outfile)\n",
    "    print(f'Combined multi tag metadata successful: {output_file}')\n",
    "    \n",
    "combine_ocr_metadata_json_file(ocr_metadata_dir, combined_ocr_metadata_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined multi tag metadata successful: tag_metadata.json\n"
     ]
    }
   ],
   "source": [
    "keyframe_metadata_file = f\"{dir_path}/keyframes_metadata.json\"\n",
    "\n",
    "def combine_multi_tag_metadata_json_file(directory, output_file, keyframe_metadata_file):\n",
    "    combined_data = {}\n",
    "    if os.path.exists(output_file):\n",
    "        with open(output_file, 'r') as existing_file:\n",
    "            combined_data = json.load(existing_file)\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith('.json'):\n",
    "            file_path = os.path.join(directory, filename)\n",
    "\n",
    "        with open(file_path, 'r') as file:\n",
    "                data = json.load(file)\n",
    "        for key, item in data.items():\n",
    "            # image name = key\n",
    "            with open(keyframe_metadata_file, \"r\") as file:\n",
    "                keyframe_data = json.load(file)\n",
    "            for keyframe_key, keyframe_item in keyframe_data.items():\n",
    "                if keyframe_item[\"frame_path\"].split(\"/\")[-1] == key:\n",
    "                    key_name = f\"{keyframe_key}_tag\"\n",
    "        \n",
    "            combined_data[key_name] = item\n",
    "    keys = list(combined_data.keys())\n",
    "    keys.sort()\n",
    "    sorted_combined_data = {i : combined_data[i] for i in keys}\n",
    "    with open(output_file, 'w') as outfile:\n",
    "        json.dump(sorted_combined_data, outfile)\n",
    "    print(f'Combined multi tag metadata successful: {output_file}') \n",
    "combine_multi_tag_metadata_json_file(tag_metadata_dir, combined_tag_metadata_filename, keyframe_metadata_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_audio_tag_metadata_json_file(keyframe_directory, audio_directory, output_file):\n",
    "    combined_data = {}\n",
    "\n",
    "    if os.path.exists(output_file):\n",
    "        with open(output_file, 'r') as existing_file:\n",
    "            combined_data = json.load(existing_file)\n",
    "\n",
    "    for keyframe_filename in os.listdir(keyframe_directory):\n",
    "        if keyframe_filename.endswith('.json'):\n",
    "            file_path = os.path.join(keyframe_directory, keyframe_filename)\n",
    "\n",
    "            with open(file_path, 'r') as file: # Open keyframe metadata json\n",
    "                data = json.load(file)\n",
    "            for key_keyframe in data.keys(): # Load key of keyframe metada\n",
    "                for audio_part_filename in os.listdir(audio_directory):\n",
    "                    if key_keyframe.split(\"_\")[0] == audio_part_filename: # Check L01, L02,....\n",
    "                        audio_sub_path = f\"{audio_directory}/{audio_part_filename}\" # Path to L01, L02,...\n",
    "                        for audio_file in os.listdir(audio_sub_path): # Choose file video V001, V002,...\n",
    "                            if key_keyframe.split(\"_\")[1] == audio_file.split(\".\")[0]: # Chech match with video\n",
    "                                audio_file_path = f\"{audio_sub_path}/{audio_file}\"\n",
    "                                with open(audio_file_path, \"r\") as f:\n",
    "                                    audio_data_list = json.load(f)\n",
    "                                for item in audio_data_list: # In each audio json is list containing a lot of dict\n",
    "                                    start, end = item[\"segment_id\"]\n",
    "                                    if (int(key_keyframe.split(\"_\")[2]) >= start) and (int(key_keyframe.split(\"_\")[2]) <= end): # Check keyframe in segment_id\n",
    "                                        combined_data[f\"{key_keyframe}_audio\"] = {\"transcription\" : item[\"transcription\"]}\n",
    "            fill_empty_audio_combined_data = {}\n",
    "            keys_combined_data = combined_data.keys() # Taking all keys in combined data dict\n",
    "            for key_keyframe in data.keys():\n",
    "                if f\"{key_keyframe}_audio\" not in keys_combined_data:\n",
    "                    fill_empty_audio_combined_data[f\"{key_keyframe}_audio\"] = {\"transcription\" : \"\"}\n",
    "            combined_data.update(fill_empty_audio_combined_data)\n",
    "    keys = list(combined_data.keys())\n",
    "    keys.sort()\n",
    "    sorted_combined_data = {i : combined_data[i] for i in keys}\n",
    "    with open(output_file, 'w') as outfile:\n",
    "        json.dump(sorted_combined_data, outfile)\n",
    "    \n",
    "combine_audio_tag_metadata_json_file(keyframes_metadata_dir, audio_metadata_dir, combined_audio_metadata_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combined final file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def combined_json_file(json_files, output_file):\n",
    "#     combined_data = {}\n",
    "    \n",
    "#     for file_name, data in json_files.items():\n",
    "#         path = data['path']\n",
    "#         key_ext = data.get('key_extension', '')\n",
    "#         with open(path, 'r') as f:\n",
    "#             json_data = json.load(f)\n",
    "#         print(f\"Preprocessing metadata file: {file_name}\")\n",
    "#         for key, data in json_data.items():\n",
    "#             if key_ext:\n",
    "#                 key = key.replace(f'_{key_ext}', '')\n",
    "#             if key not in combined_data:\n",
    "#                 combined_data[key] = {}\n",
    "                \n",
    "#             combined_data[key][key_ext] = data\n",
    "            \n",
    "#     with open(output_file, 'w') as f:\n",
    "#         json.dump(combined_data, f)\n",
    "\n",
    "#     print(f'Combined final metadata successful: {output_file}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# json_files = {\n",
    "#     'keyframe_metadata': {\n",
    "#         'path': combined_keyframes_metadata_filename,\n",
    "#         'key_extension': 'keyframe',\n",
    "#     },\n",
    "#     'object_extraction': {\n",
    "#         'path': combined_object_extraction_filename,\n",
    "#         'key_extension': 'detection'\n",
    "#     }\n",
    "# }\n",
    "\n",
    "# # combined_json_file(json_files, final_metadata_filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
